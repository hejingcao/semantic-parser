base_path = 'output/v2/model.RD.1'

train_paths = ['data/deepbank.train']
dev_path = 'output/v2/model.CI.1.transformer/outputs/best.deepbank.dev'
dev_smatch_path = 'data/deepbank.dev.smatch'
lemma_dictionary_path = 'data/deepbank.lemma_mappings.txt'

vocab_path = 'output/v2/vocabs.CI.word_threshold=1.txt'

max_steps = 100000
log_frequency = 50
checkpoint_frequency = 500

hyper_params.bucket.batch_item_count = 5000

hyper_params.pretrained_encoder.type = 'bert'
hyper_params.pretrained_encoder.bert_options.bert_path = '../../../data/bert/bert-base-cased'
hyper_params.pretrained_encoder.bert_options.subword_separator = None
hyper_params.pretrained_encoder.bert_options.project_to = 500

hyper_params.sentence_embedding.word_size = 500
hyper_params.sentence_embedding.word_dropout = 0.2
hyper_params.sentence_embedding.char_size = 0
hyper_params.sentence_embedding.mode = 'add'
hyper_params.sentence_embedding.use_layer_norm = False

hyper_params.encoder.type = 'lstm'
hyper_params.encoder.lstm_options.num_layers = 4
hyper_params.encoder.lstm_options.hidden_size = 500
hyper_params.encoder.lstm_options.input_keep_prob = 0.80

hyper_params.optimizer.type = 'adamw'
hyper_params.label_loss_type = 'label_smoothing'

hyper_params.advanced_learning.lr_reduce_method = 'cosine_with_hard_restarts'
hyper_params.advanced_learning.restart_cycles = 4